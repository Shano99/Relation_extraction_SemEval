{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5095f54b-9535-425c-a01c-f6ebb2118456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract sentences from TRAIN_FILE to output.txt and seeds file\n",
    "import re,os,random,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "422f707a-9dd3-4c4e-92ad-327ee7f64684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "# files already generated, dont run again\n",
    "# to run again, delete all files in data folder and re-run else it will get appended\n",
    "\n",
    "count_tuples=0\n",
    "t=10\n",
    "pattern = r'^\\d+\\s'\n",
    "# relationships = [[\"Cause\",\"Effect\"],[ \"Instrument\",\"Agency\"],[\"Product\",\"Producer\"],[\"Content\",\"Container\"],[\"Entity\",\"Origin\"],[\"Entity\",\"Destination\"],[\"Component\",\"Whole\"],[\"Member\",\"Collection\"],[\"Message\",\"Topic\"]]\n",
    "\n",
    "# (1) Cause-Effect\n",
    "# (2) Instrument-Agency\n",
    "# (3) Product-Producer\n",
    "# (4) Content-Container\n",
    "# (5) Entity-Origin\n",
    "# (6) Entity-Destination\n",
    "# (7) Component-Whole\n",
    "# (8) Member-Collection\n",
    "# (9) Message-Topic\n",
    "\n",
    "train_file = 'TRAIN_FILE.txt'\n",
    "e1_pattern = r'<e1>(.*?)</e1>'\n",
    "e2_pattern = r'<e2>(.*?)</e2>'\n",
    "tuples={}\n",
    "with open(train_file, 'r') as input:\n",
    "    for _ in range(0,8000):\n",
    "        sentence = input.readline().strip()\n",
    "        relation = input.readline().strip()\n",
    "        comment = input.readline()\n",
    "        blank = input.readline()\n",
    "\n",
    "        if relation[-7:] == \"(e1,e2)\":\n",
    "            e1 = relation[:relation.find('-')]\n",
    "            e2 = relation[relation.find('-')+1:relation.find('(')]\n",
    "            \n",
    "            \n",
    "        elif relation[-7:] == \"(e2,e1)\":\n",
    "            e2 = relation[:relation.find('-')]\n",
    "            e1 = relation[relation.find('-')+1:relation.find('(')]\n",
    "            \n",
    "        else:\n",
    "            e1 = \"Other\"\n",
    "            e2 = \"Other\"\n",
    "            \n",
    "        sentence_file = \"./data/\"+e1+\"_\"+e2+\"_train.txt\"\n",
    "        seeds_file = \"./data/\"+e1+\"_\"+e2+\"_seeds.txt\"\n",
    "\n",
    "        with open(sentence_file, 'a') as output:\n",
    "            # with open(seeds_file,'a') as seed:\n",
    "\n",
    "            key = e1+\"_\"+e2\n",
    "\n",
    "            e1_entity = re.findall(e1_pattern, sentence)[0]\n",
    "            e2_entity = re.findall(e2_pattern, sentence)[0]\n",
    "            # seed.write(e1_entity+\";\"+e2_entity+\"\\n\")\n",
    "            \n",
    "            if key in tuples:\n",
    "                tuples[key].append(e1_entity+\";\"+e2_entity)\n",
    "            else:\n",
    "                tuples[key]=[e1_entity+\";\"+e2_entity]\n",
    "                # seed.write(\"e1:\"+e1.upper()+\"\\n\")\n",
    "                # seed.write(\"e2:\"+e2.upper()+\"\\n\\n\")\n",
    "            \n",
    "            # if os.path.exists(seeds_file) and os.path.getsize(seeds_file) == 0:\n",
    "            #     seed.write(\"e1:\"+e1.upper()+\"\\n\")\n",
    "            #     seed.write(\"e2:\"+e2.upper()+\"\\n\\n\")\n",
    "                \n",
    "            # if os.path.getsize(seeds_file)<=195:\n",
    "            #     e1_entity = re.findall(e1_pattern, sentence)[0]\n",
    "            #     e2_entity = re.findall(e2_pattern, sentence)[0]\n",
    "            #     seed.write(e1_entity+\";\"+e2_entity+\"\\n\")\n",
    "                    \n",
    "            result_string = re.sub(pattern, '', sentence)\n",
    "            res = result_string.replace(\"<e1>\", \"<\"+e1.upper()+\">\")\n",
    "            res = res.replace(\"</e1>\", \"</\"+e1.upper()+\">\")\n",
    "            res = res.replace(\"<e2>\", \"<\"+e2.upper()+\">\")\n",
    "            res = res.replace(\"</e2>\", \"</\"+e2.upper()+\">\")\n",
    "            output.write(res+\"\\n\")\n",
    "            count_tuples+=1\n",
    "                \n",
    "print(count_tuples)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be46c143-a124-4e84-9b46-fb4916b80651",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_seeds_tuples\", \"w\") as json_file:\n",
    "    json.dump(tuples, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2efda0c2-cfeb-4dab-8bbe-24e16084c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole_Component\n",
      "471\n",
      "47\n",
      "Other_Other\n",
      "1410\n",
      "141\n",
      "Agency_Instrument\n",
      "407\n",
      "40\n",
      "Member_Collection\n",
      "78\n",
      "7\n",
      "Effect_Cause\n",
      "659\n",
      "65\n",
      "Entity_Destination\n",
      "844\n",
      "84\n",
      "Content_Container\n",
      "374\n",
      "37\n",
      "Message_Topic\n",
      "490\n",
      "49\n",
      "Producer_Product\n",
      "394\n",
      "39\n",
      "Collection_Member\n",
      "612\n",
      "61\n",
      "Entity_Origin\n",
      "568\n",
      "56\n",
      "Cause_Effect\n",
      "344\n",
      "34\n",
      "Component_Whole\n",
      "470\n",
      "47\n",
      "Topic_Message\n",
      "144\n",
      "14\n",
      "Product_Producer\n",
      "323\n",
      "32\n",
      "Origin_Entity\n",
      "148\n",
      "14\n",
      "Container_Content\n",
      "166\n",
      "16\n",
      "Instrument_Agency\n",
      "97\n",
      "9\n",
      "Destination_Entity\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for key in tuples:\n",
    "    print(key)\n",
    "    print(len(tuples[key]))\n",
    "    \n",
    "    seed_count = len(tuples[key]) // 10  # take 10% of input as seeds \n",
    "    if seed_count == 0:\n",
    "        seed_count=1\n",
    "    selected_items = random.sample(tuples[key], seed_count) # randomize the sample\n",
    "    print(len(selected_items))\n",
    "    seeds_file = \"./data/\"+key+\"_seeds.txt\"\n",
    "    e1,e2 = key.split(\"_\")\n",
    "    with open(seeds_file,'w') as seed:\n",
    "        seed.write(\"e1:\"+e1.upper()+\"\\n\")\n",
    "        seed.write(\"e2:\"+e2.upper()+\"\\n\\n\")\n",
    "        for item in selected_items:\n",
    "            seed.write(item+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0388da-842c-42a8-94fa-e4883d322fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
